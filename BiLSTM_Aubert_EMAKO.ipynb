{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RO4duq_mV6Xg"
   },
   "source": [
    "# Aubert EMAKO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v1c4-jeT4lrn"
   },
   "source": [
    "# Deep learning challenge using Bidirectional LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DjtJ3YNRUEc2"
   },
   "source": [
    "# IMPORT THE DATA FROM KAGGLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BYSkho1ponYD"
   },
   "outputs": [],
   "source": [
    "# Colab library to upload files to notebook\n",
    "from google.colab import files\n",
    "\n",
    "# Install Kaggle library\n",
    "!pip install -q kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6761,
     "status": "ok",
     "timestamp": 1578757737135,
     "user": {
      "displayName": "Marvin Paul",
      "photoUrl": "",
      "userId": "16067141650719668638"
     },
     "user_tz": -60
    },
    "id": "8KL7zq3dWsi1",
    "outputId": "4c09f222-e875-4f83-d8a4-ce86de59ed2a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-f2d7071d-a0cd-4c35-976b-ef3f76236de9\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-f2d7071d-a0cd-4c35-976b-ef3f76236de9\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving kaggle.json to kaggle.json\n"
     ]
    }
   ],
   "source": [
    "#Upload the kaggle.json file that contains the key for the Kaggle API\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5811,
     "status": "ok",
     "timestamp": 1578757744006,
     "user": {
      "displayName": "Marvin Paul",
      "photoUrl": "",
      "userId": "16067141650719668638"
     },
     "user_tz": -60
    },
    "id": "zruUFMfhooYg",
    "outputId": "7b2329c5-4ccc-4e38-a478-1119e8c72098"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
      "Downloading example_submission_test.csv to /content\n",
      "  0% 0.00/315k [00:00<?, ?B/s]\n",
      "100% 315k/315k [00:00<00:00, 43.6MB/s]\n",
      "Downloading dataset_test_no_labels.csv.zip to /content\n",
      "  0% 0.00/1.34M [00:00<?, ?B/s]\n",
      "100% 1.34M/1.34M [00:00<00:00, 88.4MB/s]\n",
      "Downloading dataset_train.csv.zip to /content\n",
      "100% 27.4M/27.4M [00:00<00:00, 38.3MB/s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!kaggle competitions download -c efreiparisdeeplearning2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1462,
     "status": "ok",
     "timestamp": 1578757745638,
     "user": {
      "displayName": "Marvin Paul",
      "photoUrl": "",
      "userId": "16067141650719668638"
     },
     "user_tz": -60
    },
    "id": "-mNk8xBjoobC",
    "outputId": "2c02dfbe-f550-48a7-cb18-9991c05ae386"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_test_no_labels.csv.zip  example_submission_test.csv  \u001b[0m\u001b[01;34msample_data\u001b[0m/\n",
      "dataset_train.csv.zip           kaggle.json\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NUvBAvABSV5d"
   },
   "source": [
    "# IMPORT THE LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 573,
     "status": "ok",
     "timestamp": 1578757852320,
     "user": {
      "displayName": "Marvin Paul",
      "photoUrl": "",
      "userId": "16067141650719668638"
     },
     "user_tz": -60
    },
    "id": "Qqu56XkTWnP5",
    "outputId": "fc3c145e-b219-45ec-8d22-b04d556bbdf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from numpy import array\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "import string\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras import regularizers\n",
    "from keras import utils as np_utils\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import models\n",
    "from keras.models import Model, Sequential, model_from_json, load_model\n",
    "from keras.layers import Input, Embedding, SpatialDropout1D, LSTM, Dense, Dropout, Activation, Flatten, Conv1D, GlobalMaxPooling1D, Concatenate, Bidirectional\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.merge import concatenate\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-rEQdfVdSM8I"
   },
   "source": [
    "# PREPARE THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29180,
     "status": "ok",
     "timestamp": 1578763694376,
     "user": {
      "displayName": "Romain LE GOAS",
      "photoUrl": "",
      "userId": "13918872157492183399"
     },
     "user_tz": -60
    },
    "id": "pJ_2O7kQ7lrm",
    "outputId": "6326b967-cdba-4f81-e60a-f3fec3cfb480"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de mots:  111909\n",
      "X train:  (392662, 2)\n",
      "y train:  (392662, 3)\n",
      "word count shape:  111908\n"
     ]
    }
   ],
   "source": [
    "# Import the test and train datasets into pandas dataframe\n",
    "df_train = pd.read_csv('dataset_train.csv.zip', compression='zip', sep='\\t')\n",
    "df_test = pd.read_csv('dataset_test_no_labels.csv.zip', compression='zip', sep='\\t')\n",
    "\n",
    "#df_train.groupby(['label'])['label'].count()\n",
    "# --> The data is balanced\n",
    "\n",
    "# Shuffle the data  \n",
    "df_train = sklearn.utils.shuffle(df_train, random_state=42)\n",
    "\n",
    "\n",
    "# Remove stopwords\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# def clean_column(col):\n",
    "#   col = col.str.lower()\n",
    "#   col = col.str.replace('[^\\w\\s]','  ')\n",
    "#   col = col.apply(lambda x: '  '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "#   return col\n",
    "\n",
    "# df_train.sentence_1 = clean_column(df_train.sentence_1)\n",
    "# df_train.sentence_2 = clean_column(df_train.sentence_2)\n",
    "\n",
    "\n",
    "# Encode the labels because the model requires numbers, not text\n",
    "label_encoder = LabelEncoder()\n",
    "df_train.label = label_encoder.fit_transform(df_train.label)\n",
    "\n",
    "X = df_train[['sentence_1', 'sentence_2']]\n",
    "y = df_train['label']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Keras models require one hot encoding for the label input\n",
    "y_train = pd.get_dummies(y_train)\n",
    "#y_test = pd.get_dummies(y_test)\n",
    "\n",
    "# Vectorize the text corpus\n",
    "word_tokenizer = Tokenizer()\n",
    "word_tokenizer.fit_on_texts(X_train.sentence_1+X_train.sentence_2)\n",
    "vocab_size = len(word_tokenizer.word_index) + 1\n",
    "# vocab_size = 10000\n",
    "max_length = 100\n",
    "\n",
    "print('vocabulary size: ', vocab_size)\n",
    "print('max length: ', max_length)\n",
    "\n",
    "# Text to sequence, then pad the sequence for the train set and the test set\n",
    "# TRAIN\n",
    "train_encoded_sentences = word_tokenizer.texts_to_sequences(X_train['sentence_1'])\n",
    "train_encoded_sentences2 = word_tokenizer.texts_to_sequences(X_train['sentence_2'])\n",
    "padded_sentences = pad_sequences(train_encoded_sentences, max_length, padding='post')\n",
    "padded_sentences2 = pad_sequences(train_encoded_sentences2, max_length, padding='post')\n",
    "\n",
    "# TEST\n",
    "# test_encoded_sentences = word_tokenizer.texts_to_sequences(X_test['sentence_1'])\n",
    "# test_encoded_sentences2 = word_tokenizer.texts_to_sequences(X_test['sentence_2'])\n",
    "# padded_sentences_test = pad_sequences(test_encoded_sentences, max_length, padding='post')\n",
    "# padded_sentences2_test = pad_sequences(test_encoded_sentences2, max_length, padding='post')\n",
    "\n",
    "print('X train shape: ', X_train.shape)\n",
    "print('y train shape: ', y_train.shape)\n",
    "# print('X test shape: ', X_test.shape)\n",
    "# print('y test shape: ', y_test.shape)\n",
    "\n",
    "print('word count shape: ', len(word_tokenizer.word_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1jTh20vSWfB0"
   },
   "source": [
    "# GLOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 417815,
     "status": "ok",
     "timestamp": 1578764091622,
     "user": {
      "displayName": "Romain LE GOAS",
      "photoUrl": "",
      "userId": "13918872157492183399"
     },
     "user_tz": -60
    },
    "id": "H6o8EL9d7lrp",
    "outputId": "21258705-5d25-4e69-b2c0-d32c43b029d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding dictionary shape:  400000\n",
      "embedding matrix shape:  (111909, 50)\n"
     ]
    }
   ],
   "source": [
    "# Let's use a pretrained glove embedding\n",
    "glove_zip_file = \"glove.6B.zip\"\n",
    "glove_vectors_file = \"glove.6B.50d.txt\"\n",
    "\n",
    "if (not os.path.isfile(glove_zip_file) and\n",
    "    not os.path.isfile(glove_vectors_file)):\n",
    "    urllib.request.urlretrieve (\"http://nlp.stanford.edu/data/glove.6B.zip\", \n",
    "                 glove_zip_file)\n",
    "    \n",
    "\n",
    "def unzip_single_file(zip_file_name, output_file_name):\n",
    "# If the outFile is already created, don't recreate\n",
    "# If the outFile does not exist, create it from the zipFile\n",
    "    if not os.path.isfile(output_file_name):\n",
    "        with open(output_file_name, 'wb') as out_file:\n",
    "            with zipfile.ZipFile(zip_file_name) as zipped:\n",
    "                for info in zipped.infolist():\n",
    "                    if output_file_name in info.filename:\n",
    "                        with zipped.open(info) as requested_file:\n",
    "                            out_file.write(requested_file.read())\n",
    "                            return\n",
    "\n",
    "unzip_single_file(glove_zip_file, glove_vectors_file)\n",
    "\n",
    "embeddings_dictionary = dict()\n",
    "\n",
    "glove_wordmap = {}\n",
    "with open(glove_vectors_file, \"r\") as glove:\n",
    "    for line in glove:\n",
    "        records = line.split()\n",
    "        word = records[0]\n",
    "        vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "        embeddings_dictionary [word] = vector_dimensions\n",
    "    glove.close()\n",
    "\n",
    "embedding_matrix = zeros((vocab_size, 50))\n",
    "for word, index in word_tokenizer.word_index.items():\n",
    "  embedding_vector = embeddings_dictionary.get(word)\n",
    "  if embedding_vector is not None:\n",
    "    embedding_matrix[index] = embedding_vector\n",
    "\n",
    "\n",
    "print('embedding dictionary shape: ', len(embeddings_dictionary))\n",
    "print('embedding matrix shape: ', embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0tYLLortSD0H"
   },
   "source": [
    "# MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2411,
     "status": "ok",
     "timestamp": 1578766105606,
     "user": {
      "displayName": "Romain LE GOAS",
      "photoUrl": "",
      "userId": "13918872157492183399"
     },
     "user_tz": -60
    },
    "id": "AIsQfm5N7lrs",
    "outputId": "c65a3349-2413-4fba-b1f0-4f7b9f6fbbad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 100, 50)      5595450     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 100, 50)      5595450     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 100, 128)     58880       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 100, 128)     58880       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 100, 128)     0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 100, 128)     0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 12800)        0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 12800)        0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 25600)        0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           1638464     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3)            195         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 12,947,319\n",
      "Trainable params: 1,756,419\n",
      "Non-trainable params: 11,190,900\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 333762 samples, validate on 58900 samples\n",
      "Epoch 1/10\n",
      "333762/333762 [==============================] - 194s 580us/step - loss: 1.0372 - acc: 0.4522 - val_loss: 1.0079 - val_acc: 0.4832\n",
      "Epoch 2/10\n",
      "333762/333762 [==============================] - 189s 566us/step - loss: 0.9802 - acc: 0.5094 - val_loss: 0.9680 - val_acc: 0.5230\n",
      "Epoch 3/10\n",
      "333762/333762 [==============================] - 187s 559us/step - loss: 0.9519 - acc: 0.5341 - val_loss: 0.9514 - val_acc: 0.5367\n",
      "Epoch 4/10\n",
      "333762/333762 [==============================] - 187s 561us/step - loss: 0.9308 - acc: 0.5519 - val_loss: 0.9401 - val_acc: 0.5438\n",
      "Epoch 5/10\n",
      "333762/333762 [==============================] - 185s 555us/step - loss: 0.9123 - acc: 0.5653 - val_loss: 0.9305 - val_acc: 0.5529\n",
      "Epoch 6/10\n",
      "333762/333762 [==============================] - 180s 539us/step - loss: 0.8951 - acc: 0.5774 - val_loss: 0.9223 - val_acc: 0.5592\n",
      "Epoch 7/10\n",
      "333762/333762 [==============================] - 178s 532us/step - loss: 0.8796 - acc: 0.5882 - val_loss: 0.9224 - val_acc: 0.5602\n",
      "Epoch 8/10\n",
      "333762/333762 [==============================] - 177s 529us/step - loss: 0.8643 - acc: 0.5979 - val_loss: 0.9242 - val_acc: 0.5623\n",
      "Epoch 9/10\n",
      "333762/333762 [==============================] - 177s 532us/step - loss: 0.8509 - acc: 0.6068 - val_loss: 0.9237 - val_acc: 0.5623\n",
      "Epoch 10/10\n",
      "333762/333762 [==============================] - 177s 531us/step - loss: 0.8353 - acc: 0.6160 - val_loss: 0.9324 - val_acc: 0.5612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc40a02c588>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying Embedding and Bidirectional LSTM to both sentences separately, then using dropout and flattening\n",
    "input1 = Input(shape=(padded_sentences.shape[1],))\n",
    "x1 = Embedding(vocab_size, 50, weights=[embedding_matrix], input_length=max_length, trainable=False)(input1)\n",
    "x1 = Bidirectional(LSTM(64, return_sequences=True))(x1)\n",
    "x1 = Dropout(0.3)(x1)\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "input2 = Input(shape=(padded_sentences2.shape[1],))\n",
    "x2 = Embedding(vocab_size, 50, weights=[embedding_matrix], input_length=max_length, trainable=False)(input2)\n",
    "x2 = Bidirectional(LSTM(64, return_sequences=True))(x2)\n",
    "x2 = Dropout(0.3)(x2)\n",
    "x2 = Flatten()(x2)\n",
    "\n",
    "# Concatenates the two outputs\n",
    "out = concatenate([x1, x2])\n",
    "\n",
    "#interpretation\n",
    "\n",
    "out = Dense(64, activation='relu')(out)\n",
    "out = Dense(3, activation='softmax')(out) \n",
    "\n",
    "model = Model(inputs=[input1, input2], outputs=out)\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "batch_size = 1024\n",
    "\n",
    "model.fit([padded_sentences, padded_sentences2], y_train, batch_size = batch_size, epochs = 10, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E1sZE8DOsfqX"
   },
   "outputs": [],
   "source": [
    "#To see the results on the testing part of the dataset if the data is split when preparing the data\n",
    "# score = model.evaluate([padded_sentences_test, padded_sentences2_test], y_test)\n",
    "# print('Test data loss:', score[0])\n",
    "# print('Test data accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VoizmxGH7lrw"
   },
   "source": [
    "# Prediction of the labels for the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 127635,
     "status": "ok",
     "timestamp": 1578766312907,
     "user": {
      "displayName": "Romain LE GOAS",
      "photoUrl": "",
      "userId": "13918872157492183399"
     },
     "user_tz": -60
    },
    "id": "jZ4kwvyr7lrw",
    "outputId": "fb91a813-db45-47a4-8100-93be9377ecd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['entailment' 'neutral' 'entailment' ... 'contradiction' 'neutral'\n",
      " 'neutral']\n",
      "(19647, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index          label\n",
       "0      0     entailment\n",
       "1      1        neutral\n",
       "2      2     entailment\n",
       "3      3     entailment\n",
       "4      4  contradiction"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = df_test[['sentence_1', 'sentence_2']]\n",
    "\n",
    "sumbit_encoded_sentences = word_tokenizer.texts_to_sequences(test_X['sentence_1'])\n",
    "sumbit_encoded_sentences2 = word_tokenizer.texts_to_sequences(test_X['sentence_2'])\n",
    "\n",
    "submit_padded = pad_sequences(sumbit_encoded_sentences, max_length, padding='post')\n",
    "submit_padded2 = pad_sequences(sumbit_encoded_sentences2, max_length, padding='post')\n",
    "\n",
    "predicted_labels = model.predict([submit_padded, submit_padded2]).argmax(axis=1)\n",
    "predicted_labels = label_encoder.inverse_transform(predicted_labels)\n",
    "print(predicted_labels)\n",
    "\n",
    "my_submission = pd.DataFrame({'index': test_X.index, 'label': predicted_labels})\n",
    "my_submission.to_csv('submission.csv', index=False)\n",
    "print(my_submission.shape)\n",
    "my_submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "27ODHpk76qis"
   },
   "outputs": [],
   "source": [
    "#Download the file for submission\n",
    "files.download('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "DjtJ3YNRUEc2",
    "NUvBAvABSV5d",
    "-rEQdfVdSM8I",
    "1jTh20vSWfB0",
    "0tYLLortSD0H",
    "VoizmxGH7lrw"
   ],
   "machine_shape": "hm",
   "name": "BiLSTM_BEYER_PAUL_LE GOAS.ipynb",
   "provenance": [
    {
     "file_id": "1GU7vGrWYv752F5sBh5y4KVmfmxeSOaeb",
     "timestamp": 1578669096233
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
